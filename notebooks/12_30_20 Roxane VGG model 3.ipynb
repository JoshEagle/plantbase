{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../raw_data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=90,\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3460 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    path,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 857 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = valid_datagen.flow_from_directory(\n",
    "    path, # same directory as training data\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight = {0:4. ,\n",
    "#                 1:2., \n",
    "#                 2:1.5 ,\n",
    "#                 3:2.,\n",
    "#                 4:3.,\n",
    "#                 5:2.,\n",
    "#                 6:1.5,\n",
    "#                 7:4.,\n",
    "#                 8:2.,\n",
    "#                 9:3.,\n",
    "#                 10:1.,\n",
    "#                 11:4.,\n",
    "#                 12:3.,\n",
    "#                 13:2.,\n",
    "#                 14:3.,\n",
    "#                 15:2.\n",
    "#                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              134221824 \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                65552     \n",
      "=================================================================\n",
      "Total params: 165,783,376\n",
      "Trainable params: 65,552\n",
      "Non-trainable params: 165,717,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(256,256,3))\n",
    "\n",
    "model=Sequential()\n",
    "for layers in vgg16_model.layers:\n",
    "    model.add(layers)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096,activation='relu'))\n",
    "model.add(Dense(4096,activation='relu'))\n",
    "for layer in model.layers:\n",
    "    layer.trainable=False\n",
    "model.add(Dense(16,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the first layers to be untrainable\n",
    "# model.trainable = False\n",
    "# # Add layers to the mdoel\n",
    "# flatten_layer = layers.Flatten()\n",
    "# dense_layer = layers.Dense(100, activation='relu')\n",
    "# prediction_layer = layers.Dense(16, activation='softmax')\n",
    "\n",
    "# model = Sequential([model,\n",
    "#                     flatten_layer,\n",
    "#                     dense_layer,\n",
    "#                     prediction_layer])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=optimizers.SGD(learning_rate = 0.1),\n",
    "#           loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "#           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=RMSprop(lr=0.001,rho=0.9,epsilon=1e-08,decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer,loss=SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction=ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.5,minlr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = EarlyStopping(\n",
    "#     monitor='val_loss',\n",
    "#     patience=3,\n",
    "#     mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.6477 - accuracy: 0.1604WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 669s 6s/step - loss: 2.6477 - accuracy: 0.1604 - val_loss: 2.5852 - val_accuracy: 0.1839\n",
      "Epoch 2/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.5355 - accuracy: 0.2908WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 679s 6s/step - loss: 2.5355 - accuracy: 0.2908 - val_loss: 2.4919 - val_accuracy: 0.3810\n",
      "Epoch 3/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.4711 - accuracy: 0.3696WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 841s 8s/step - loss: 2.4711 - accuracy: 0.3696 - val_loss: 2.4452 - val_accuracy: 0.3846\n",
      "Epoch 4/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.4308 - accuracy: 0.3929WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 820s 8s/step - loss: 2.4308 - accuracy: 0.3929 - val_loss: 2.4087 - val_accuracy: 0.4387\n",
      "Epoch 5/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.3996 - accuracy: 0.4414WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 836s 8s/step - loss: 2.3996 - accuracy: 0.4414 - val_loss: 2.3873 - val_accuracy: 0.4736\n",
      "Epoch 6/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.3763 - accuracy: 0.4522 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 2925s 27s/step - loss: 2.3763 - accuracy: 0.4522 - val_loss: 2.3669 - val_accuracy: 0.4688\n",
      "Epoch 7/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.3580 - accuracy: 0.4883 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 3187s 30s/step - loss: 2.3580 - accuracy: 0.4883 - val_loss: 2.3471 - val_accuracy: 0.5300\n",
      "Epoch 8/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.3418 - accuracy: 0.4927  WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 15494s 143s/step - loss: 2.3418 - accuracy: 0.4927 - val_loss: 2.3565 - val_accuracy: 0.4603\n",
      "Epoch 9/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.3275 - accuracy: 0.5099 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 1767s 16s/step - loss: 2.3275 - accuracy: 0.5099 - val_loss: 2.3292 - val_accuracy: 0.5120\n",
      "Epoch 10/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.3259 - accuracy: 0.5166 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 2402s 22s/step - loss: 2.3259 - accuracy: 0.5166 - val_loss: 2.3208 - val_accuracy: 0.5469\n",
      "Epoch 11/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.3098 - accuracy: 0.5260WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 924s 9s/step - loss: 2.3098 - accuracy: 0.5260 - val_loss: 2.3249 - val_accuracy: 0.5264\n",
      "Epoch 12/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.3037 - accuracy: 0.5452WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 830s 8s/step - loss: 2.3037 - accuracy: 0.5452 - val_loss: 2.2936 - val_accuracy: 0.5469\n",
      "Epoch 13/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.2915 - accuracy: 0.5508WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 677s 6s/step - loss: 2.2915 - accuracy: 0.5508 - val_loss: 2.2996 - val_accuracy: 0.5409\n",
      "Epoch 14/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.2868 - accuracy: 0.5648WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 778s 7s/step - loss: 2.2868 - accuracy: 0.5648 - val_loss: 2.2975 - val_accuracy: 0.5505\n",
      "Epoch 15/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.2829 - accuracy: 0.5621WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 804s 7s/step - loss: 2.2829 - accuracy: 0.5621 - val_loss: 2.2908 - val_accuracy: 0.5349\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // 32,\n",
    "    validation_data = val_generator,\n",
    "    validation_steps = val_generator.samples // 32,\n",
    "    epochs = 15,\n",
    "    callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/momeni/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/momeni/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ../model/roxane_vgg_3/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(r'../model/roxane_vgg_3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
