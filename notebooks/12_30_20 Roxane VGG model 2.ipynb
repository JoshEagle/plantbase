{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../raw_data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=90,\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3460 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    path,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 857 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = valid_datagen.flow_from_directory(\n",
    "    path, # same directory as training data\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              134221824 \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                65552     \n",
      "=================================================================\n",
      "Total params: 165,783,376\n",
      "Trainable params: 65,552\n",
      "Non-trainable params: 165,717,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = VGG16(include_top=False, input_shape=(256,256,3))\n",
    "\n",
    "model=Sequential()\n",
    "for layers in vgg16_model.layers:\n",
    "    model.add(layers)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096,activation='relu'))\n",
    "model.add(Dense(4096,activation='relu'))\n",
    "for layer in model.layers:\n",
    "    layer.trainable=False\n",
    "model.add(Dense(16,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the first layers to be untrainable\n",
    "# model.trainable = False\n",
    "# # Add layers to the mdoel\n",
    "# flatten_layer = layers.Flatten()\n",
    "# dense_layer = layers.Dense(100, activation='relu')\n",
    "# prediction_layer = layers.Dense(16, activation='softmax')\n",
    "\n",
    "# model = Sequential([model,\n",
    "#                     flatten_layer,\n",
    "#                     dense_layer,\n",
    "#                     prediction_layer])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=optimizers.SGD(learning_rate = 0.1),\n",
    "#           loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "#           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=RMSprop(lr=0.001,rho=0.9,epsilon=1e-08,decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer,loss=SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy',patience=3,verbose=1,factor=0.5,minlr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = EarlyStopping(\n",
    "#     monitor='val_loss',\n",
    "#     patience=3,\n",
    "#     mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "108/108 [==============================] - 880s 8s/step - loss: 2.6897 - accuracy: 0.1820 - val_loss: 2.6611 - val_accuracy: 0.2320\n",
      "Epoch 2/30\n",
      "108/108 [==============================] - 616s 6s/step - loss: 2.6377 - accuracy: 0.2462 - val_loss: 2.6195 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "108/108 [==============================] - 628s 6s/step - loss: 2.6023 - accuracy: 0.2943 - val_loss: 2.5673 - val_accuracy: 0.3389\n",
      "Epoch 4/30\n",
      "108/108 [==============================] - 633s 6s/step - loss: 2.5747 - accuracy: 0.3264 - val_loss: 2.5546 - val_accuracy: 0.3401\n",
      "Epoch 5/30\n",
      "108/108 [==============================] - 648s 6s/step - loss: 2.5563 - accuracy: 0.3431 - val_loss: 2.5360 - val_accuracy: 0.3642\n",
      "Epoch 6/30\n",
      "108/108 [==============================] - 694s 6s/step - loss: 2.5432 - accuracy: 0.3539 - val_loss: 2.5302 - val_accuracy: 0.3582\n",
      "Epoch 7/30\n",
      "108/108 [==============================] - 672s 6s/step - loss: 2.5394 - accuracy: 0.3562 - val_loss: 2.5209 - val_accuracy: 0.3798\n",
      "Epoch 8/30\n",
      "108/108 [==============================] - 677s 6s/step - loss: 2.5305 - accuracy: 0.3617 - val_loss: 2.5284 - val_accuracy: 0.3534\n",
      "Epoch 9/30\n",
      "108/108 [==============================] - 695s 6s/step - loss: 2.5241 - accuracy: 0.3684 - val_loss: 2.5062 - val_accuracy: 0.3846\n",
      "Epoch 10/30\n",
      "108/108 [==============================] - 663s 6s/step - loss: 2.5160 - accuracy: 0.3734 - val_loss: 2.4999 - val_accuracy: 0.3894\n",
      "Epoch 11/30\n",
      "108/108 [==============================] - 655s 6s/step - loss: 2.5140 - accuracy: 0.3807 - val_loss: 2.5048 - val_accuracy: 0.3906\n",
      "Epoch 12/30\n",
      "108/108 [==============================] - 648s 6s/step - loss: 2.5120 - accuracy: 0.3772 - val_loss: 2.5054 - val_accuracy: 0.3870\n",
      "Epoch 13/30\n",
      "108/108 [==============================] - 643s 6s/step - loss: 2.5092 - accuracy: 0.3792 - val_loss: 2.4992 - val_accuracy: 0.3834\n",
      "Epoch 14/30\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.5061 - accuracy: 0.3807\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "108/108 [==============================] - 1107s 10s/step - loss: 2.5061 - accuracy: 0.3807 - val_loss: 2.5021 - val_accuracy: 0.3870\n",
      "Epoch 15/30\n",
      "108/108 [==============================] - 628s 6s/step - loss: 2.5011 - accuracy: 0.3819 - val_loss: 2.4858 - val_accuracy: 0.3990\n",
      "Epoch 16/30\n",
      "108/108 [==============================] - 3718s 34s/step - loss: 2.4975 - accuracy: 0.3915 - val_loss: 2.4835 - val_accuracy: 0.4014\n",
      "Epoch 17/30\n",
      "108/108 [==============================] - 1559s 14s/step - loss: 2.4996 - accuracy: 0.3886 - val_loss: 2.4884 - val_accuracy: 0.3954\n",
      "Epoch 18/30\n",
      "108/108 [==============================] - 638s 6s/step - loss: 2.4951 - accuracy: 0.3941 - val_loss: 2.4874 - val_accuracy: 0.3966\n",
      "Epoch 19/30\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.4913 - accuracy: 0.3964\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "108/108 [==============================] - 664s 6s/step - loss: 2.4913 - accuracy: 0.3964 - val_loss: 2.4901 - val_accuracy: 0.3882\n",
      "Epoch 20/30\n",
      "108/108 [==============================] - 661s 6s/step - loss: 2.4913 - accuracy: 0.3988 - val_loss: 2.4871 - val_accuracy: 0.3930\n",
      "Epoch 21/30\n",
      "108/108 [==============================] - 687s 6s/step - loss: 2.4929 - accuracy: 0.3973 - val_loss: 2.4855 - val_accuracy: 0.4002\n",
      "Epoch 22/30\n",
      "108/108 [==============================] - 2852s 26s/step - loss: 2.4882 - accuracy: 0.4023 - val_loss: 2.4824 - val_accuracy: 0.4062\n",
      "Epoch 23/30\n",
      "108/108 [==============================] - 2459s 23s/step - loss: 2.4862 - accuracy: 0.4026 - val_loss: 2.4824 - val_accuracy: 0.4050\n",
      "Epoch 24/30\n",
      "108/108 [==============================] - 3745s 35s/step - loss: 2.4906 - accuracy: 0.3970 - val_loss: 2.4796 - val_accuracy: 0.4062\n",
      "Epoch 25/30\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.4889 - accuracy: 0.3994\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "108/108 [==============================] - 650s 6s/step - loss: 2.4889 - accuracy: 0.3994 - val_loss: 2.4829 - val_accuracy: 0.4002\n",
      "Epoch 26/30\n",
      "108/108 [==============================] - 674s 6s/step - loss: 2.4911 - accuracy: 0.3921 - val_loss: 2.4812 - val_accuracy: 0.4002\n",
      "Epoch 27/30\n",
      "108/108 [==============================] - 656s 6s/step - loss: 2.4885 - accuracy: 0.4008 - val_loss: 2.4824 - val_accuracy: 0.4026\n",
      "Epoch 28/30\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.4860 - accuracy: 0.4064\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "108/108 [==============================] - 673s 6s/step - loss: 2.4860 - accuracy: 0.4064 - val_loss: 2.4824 - val_accuracy: 0.4026\n",
      "Epoch 29/30\n",
      "108/108 [==============================] - 650s 6s/step - loss: 2.4873 - accuracy: 0.3982 - val_loss: 2.4842 - val_accuracy: 0.4014\n",
      "Epoch 30/30\n",
      "108/108 [==============================] - 647s 6s/step - loss: 2.4840 - accuracy: 0.4052 - val_loss: 2.4837 - val_accuracy: 0.3966\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // 32,\n",
    "    validation_data = val_generator,\n",
    "    validation_steps = val_generator.samples // 32,\n",
    "    epochs = 30,\n",
    "    callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/momeni/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/momeni/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ../model/roxane_vgg_1/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(r'../model/roxane_vgg_2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
