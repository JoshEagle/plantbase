{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../raw_data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=90,\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3460 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    path,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 857 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = valid_datagen.flow_from_directory(\n",
    "    path, # same directory as training data\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0:4. ,\n",
    "                1:2., \n",
    "                2:1.5 ,\n",
    "                3:2.,\n",
    "                4:3.,\n",
    "                5:2.,\n",
    "                6:1.5,\n",
    "                7:4.,\n",
    "                8:2.,\n",
    "                9:3.,\n",
    "                10:1.,\n",
    "                11:4.,\n",
    "                12:3.,\n",
    "                13:2.,\n",
    "                14:3.,\n",
    "                15:2.\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              134221824 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                65552     \n",
      "=================================================================\n",
      "Total params: 165,783,376\n",
      "Trainable params: 65,552\n",
      "Non-trainable params: 165,717,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = VGG16(include_top=False, input_shape=(256,256,3))\n",
    "\n",
    "model=Sequential()\n",
    "for layers in vgg16_model.layers:\n",
    "    model.add(layers)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096,activation='relu'))\n",
    "model.add(Dense(4096,activation='relu'))\n",
    "for layer in model.layers:\n",
    "    layer.trainable=False\n",
    "model.add(Dense(16,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the first layers to be untrainable\n",
    "# model.trainable = False\n",
    "# # Add layers to the mdoel\n",
    "# flatten_layer = layers.Flatten()\n",
    "# dense_layer = layers.Dense(100, activation='relu')\n",
    "# prediction_layer = layers.Dense(16, activation='softmax')\n",
    "\n",
    "# model = Sequential([model,\n",
    "#                     flatten_layer,\n",
    "#                     dense_layer,\n",
    "#                     prediction_layer])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=optimizers.SGD(learning_rate = 0.1),\n",
    "#           loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "#           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=RMSprop(lr=0.001,rho=0.9,epsilon=1e-08,decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer,loss=SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction=ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.5,minlr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = EarlyStopping(\n",
    "#     monitor='val_loss',\n",
    "#     patience=3,\n",
    "#     mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.7057 - accuracy: 0.1628WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 914s 8s/step - loss: 2.7057 - accuracy: 0.1628 - val_loss: 2.6780 - val_accuracy: 0.2103\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.6515 - accuracy: 0.2293WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 855s 8s/step - loss: 2.6515 - accuracy: 0.2293 - val_loss: 2.6282 - val_accuracy: 0.2464\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.6194 - accuracy: 0.2660WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 879s 8s/step - loss: 2.6194 - accuracy: 0.2660 - val_loss: 2.6034 - val_accuracy: 0.2897\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.5975 - accuracy: 0.2928WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 845s 8s/step - loss: 2.5975 - accuracy: 0.2928 - val_loss: 2.5980 - val_accuracy: 0.2945\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.5777 - accuracy: 0.3168WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 834s 8s/step - loss: 2.5777 - accuracy: 0.3168 - val_loss: 2.5903 - val_accuracy: 0.2849\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.5709 - accuracy: 0.3139WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 863s 8s/step - loss: 2.5709 - accuracy: 0.3139 - val_loss: 2.5659 - val_accuracy: 0.3245\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.5612 - accuracy: 0.3296WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 896s 8s/step - loss: 2.5612 - accuracy: 0.3296 - val_loss: 2.5454 - val_accuracy: 0.3413\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.5535 - accuracy: 0.3369WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 721s 7s/step - loss: 2.5535 - accuracy: 0.3369 - val_loss: 2.5626 - val_accuracy: 0.3269\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.5467 - accuracy: 0.3401WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 750s 7s/step - loss: 2.5467 - accuracy: 0.3401 - val_loss: 2.5417 - val_accuracy: 0.3413\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - ETA: 0s - loss: 2.5404 - accuracy: 0.3477WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "108/108 [==============================] - 917s 8s/step - loss: 2.5404 - accuracy: 0.3477 - val_loss: 2.5348 - val_accuracy: 0.3546\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // 32,\n",
    "    validation_data = val_generator,\n",
    "    validation_steps = val_generator.samples // 32,\n",
    "    epochs = 20,\n",
    "    callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/momeni/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/momeni/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ../model/roxane_vgg_1/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(r'../model/roxane_vgg_1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
